{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7d2d0f6ae0f468e82afd701af0783f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a272347665be4a8a8a91c270016ff138",
              "IPY_MODEL_9a87ab58653546be9758ebb380bbbb33",
              "IPY_MODEL_729c392cb94d450f905dc6f11b0f6148"
            ],
            "layout": "IPY_MODEL_92609697f09c43adb09c5104ccdda5f0"
          }
        },
        "a272347665be4a8a8a91c270016ff138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_127b0f58df1643c28a381d4e95d8a112",
            "placeholder": "​",
            "style": "IPY_MODEL_4bdbe958ce024b778afae20f254b24a9",
            "value": "model.pt: 100%"
          }
        },
        "9a87ab58653546be9758ebb380bbbb33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9558f34f96c044b2ae0397df1dd6ffed",
            "max": 6247065,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7863a61edb841569bec5ffb6d415a31",
            "value": 6247065
          }
        },
        "729c392cb94d450f905dc6f11b0f6148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4962e4280a4d73ba2f9ecf80dde175",
            "placeholder": "​",
            "style": "IPY_MODEL_972951f3f18449d8aac48220d19c3670",
            "value": " 6.25M/6.25M [00:00&lt;00:00, 28.9MB/s]"
          }
        },
        "92609697f09c43adb09c5104ccdda5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127b0f58df1643c28a381d4e95d8a112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdbe958ce024b778afae20f254b24a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9558f34f96c044b2ae0397df1dd6ffed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7863a61edb841569bec5ffb6d415a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be4962e4280a4d73ba2f9ecf80dde175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "972951f3f18449d8aac48220d19c3670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Merging the two models built before\n",
        "This notebook aims to merge the two notebooks we had seen before, the first model is trained on coco8 dataset.  The second model is pre-trained for face detection found on hugging face. Both are YOLO models.\n",
        "\n",
        "source: https://huggingface.co/arnabdhar/YOLOv8-Face-Detection\n",
        "\n",
        "\n",
        "**Note** : Merging here does **NOT** reffer to combining the two models, its simply to put both of them in the same notebook and see what we can do with them since we are just testing.(**Why?** Because we have not finalized our models yet.) We will obviously add benchmarks at the end.\n",
        "\n",
        "Benchmarks, i.e the speed taken for both the models is given below including the performances"
      ],
      "metadata": {
        "id": "eQAX-lMvPlo5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8Y8mGmq4z48"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision"
      ],
      "metadata": {
        "id": "eJNu8THO5AM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hOFIGcK042ib"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from tabulate import tabulate\n",
        "from huggingface_hub import hf_hub_download\n",
        "from supervision import Detections\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "HN49Z_kK43s6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.pt') # load a pre-trained model\n",
        "model.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jf5L7zv45cA",
        "outputId": "230f58b0-6bc4-459c-e471-ae3d526bc08c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 57.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8n summary: 225 layers, 3157200 parameters, 0 gradients, 8.9 GFLOPs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(225, 3157200, 0, 8.8575488)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.train(data='coco8.yaml', epochs=100, imgsz=640)"
      ],
      "metadata": {
        "id": "NI1s3Rwd46hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download model\n",
        "model_path = hf_hub_download(repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")\n",
        "\n",
        "# load model\n",
        "face_model = YOLO(model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "e7d2d0f6ae0f468e82afd701af0783f8",
            "a272347665be4a8a8a91c270016ff138",
            "9a87ab58653546be9758ebb380bbbb33",
            "729c392cb94d450f905dc6f11b0f6148",
            "92609697f09c43adb09c5104ccdda5f0",
            "127b0f58df1643c28a381d4e95d8a112",
            "4bdbe958ce024b778afae20f254b24a9",
            "9558f34f96c044b2ae0397df1dd6ffed",
            "a7863a61edb841569bec5ffb6d415a31",
            "be4962e4280a4d73ba2f9ecf80dde175",
            "972951f3f18449d8aac48220d19c3670"
          ]
        },
        "id": "WA0j-QNk48Hx",
        "outputId": "5aceb983-9d30-42ef-e6f4-4a9352933a81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.pt:   0%|          | 0.00/6.25M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7d2d0f6ae0f468e82afd701af0783f8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_side_by_side(image1, image2):\n",
        "    \"\"\"\n",
        "    Display two images side by side.\n",
        "\n",
        "    Parameters:\n",
        "        image1 (numpy.ndarray): The first image.\n",
        "        image2 (numpy.ndarray): The second image.\n",
        "    \"\"\"\n",
        "    concatenated_image = cv2.hconcat([image1, image2])\n",
        "\n",
        "    cv2_imshow(concatenated_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "XqX_Oe3y5Ohv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/images\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCqfAdL0JrXj",
        "outputId": "20d1c455-6458-4c0e-93d7-a9b7a4d34850"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/images\n",
            "001.png  002.jpg  003.jpeg  004.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [\"001.png\",  \"002.jpg\",  \"003.jpeg\", \"004.png\"]\n",
        "image_results = []\n",
        "saved_paths = []\n",
        "\n",
        "for path in paths:\n",
        "    filename, extension = os.path.splitext(path)\n",
        "    save_path = f\"{filename}_result{extension}\"\n",
        "\n",
        "    curr_result = model(path)[0]\n",
        "    curr_result[0].save(save_path)\n",
        "\n",
        "    image_results.append(curr_result)\n",
        "    saved_paths.append(save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuFwgYYqL90a",
        "outputId": "172358cb-cecd-4ad2-dfcf-c9b75fcc2aaa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/images/001.png: 384x640 2 persons, 1 car, 172.4ms\n",
            "Speed: 2.7ms preprocess, 172.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/images/002.jpg: 416x640 24 persons, 1 tie, 162.4ms\n",
            "Speed: 3.4ms preprocess, 162.4ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/images/003.jpeg: 640x640 1 bear, 252.0ms\n",
            "Speed: 3.9ms preprocess, 252.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/images/004.png: 384x640 1 bottle, 2 wine glasss, 1 cup, 2 forks, 3 knifes, 2 spoons, 1 bowl, 2 dining tables, 162.8ms\n",
            "Speed: 3.0ms preprocess, 162.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMMENTED OUT TO REDUCE PYNB SIZE, output saved in images folder\n",
        "\n",
        "# for input, output in zip(paths, saved_paths):\n",
        "#   image1 = cv2.imread(input)\n",
        "#   image2 = cv2.imread(output)\n",
        "#   display_side_by_side(image1, image2)\n"
      ],
      "metadata": {
        "id": "837L-aSGMVcf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_paths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlUqHPTMM-cv",
        "outputId": "055aeac5-948e-40b3-82f4-515796b8ae90"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['001_result.png', '002_result.jpg', '003_result.jpeg', '004_result.png']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_results_2 = []\n",
        "face_paths = []\n",
        "for path in paths:\n",
        "    filename, extension = os.path.splitext(path)\n",
        "    save_path = f\"{filename}_face_result{extension}\"\n",
        "\n",
        "    curr_result = face_model(path)[0]\n",
        "    curr_result[0].save(save_path)\n",
        "\n",
        "    image_results_2.append(curr_result)\n",
        "    face_paths.append(save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "nopVlcJmMZk_",
        "outputId": "77a84cf3-e182-4296-c21f-ae2d963542e8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/images/001.png: 384x640 3 FACEs, 608.7ms\n",
            "Speed: 6.6ms preprocess, 608.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/images/002.jpg: 416x640 24 FACEs, 1172.9ms\n",
            "Speed: 92.1ms preprocess, 1172.9ms inference, 2.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/images/003.jpeg: 640x640 1 FACE, 341.5ms\n",
            "Speed: 8.6ms preprocess, 341.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/images/004.png: 384x640 (no detections), 167.1ms\n",
            "Speed: 3.4ms preprocess, 167.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for dimension 0 with size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8fb9a9898ca9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcurr_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcurr_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimage_results_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/results.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;34m\"\"\"Return a Results object for the specified index.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__getitem__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/results.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/results.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m\"\"\"Return a BaseTensor with the specified index of the data tensor.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_paths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O95uaut8M4yb",
        "outputId": "cc719293-1d55-4893-b4e1-3c526c28c16a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['001_result_face_result.png',\n",
              " '002_result_face_result.jpg',\n",
              " '003_result_face_result.jpeg']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = []\n",
        "\n",
        "for result in image_results:\n",
        "    speed = result.speed\n",
        "    orig_shape = result.orig_shape\n",
        "    image_data.append((orig_shape, speed['preprocess'], speed['inference'], speed['postprocess']))\n",
        "\n",
        "print(tabulate(image_data, headers=[ \"Original Shape\",\"Preprocess\", \"Inference\", \"Postprocess\",]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS7aXenYM6M3",
        "outputId": "a10ddaf9-a0ee-4b7f-f184-b276130c7852"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Shape      Preprocess    Inference    Postprocess\n",
            "----------------  ------------  -----------  -------------\n",
            "(168, 300)             2.71463      172.394        1.44792\n",
            "(480, 768)             3.41344      162.386        1.98889\n",
            "(225, 225)             3.90077      251.972        1.68943\n",
            "(514, 875)             2.9695       162.759        1.84631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_data_2 = []\n",
        "\n",
        "for result in image_results_2:\n",
        "    speed = result.speed\n",
        "    orig_shape = result.orig_shape\n",
        "    image_data_2.append((orig_shape, speed['preprocess'], speed['inference'], speed['postprocess']))\n",
        "\n",
        "print(tabulate(image_data_2, headers=[ \"Original Shape\",\"Preprocess\", \"Inference\", \"Postprocess\",]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElJkyPKFN4RD",
        "outputId": "5f74d512-8275-48b6-da74-f89e9e6e26c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Shape      Preprocess    Inference    Postprocess\n",
            "----------------  ------------  -----------  -------------\n",
            "(168, 300)             3.63016      199.303        2.563\n",
            "(480, 768)             3.582        160.225        1.28984\n",
            "(225, 225)             4.67849      254.233        1.26791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n",
        "- The first model was properly able to detect all 24 persons in the second image, funfact the image is actually 24 AI generated faces ! It categorized all of them as Persons.\n",
        "- The second model was able to detect three faces, including the person who is barely visible behind one of the people present in the scene.\n",
        "- The second model was able to detect 24 faces in the second image as well\n",
        "- The second model threw an error in the lats image, which had no faces, indicating it detects the presence of no face, which is exactly what we need.\n",
        "\n",
        "- The time taken for each image is roughly the same for both the models"
      ],
      "metadata": {
        "id": "hDevjwprOEkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Future Work\n",
        "We now have models which can\n",
        "- Detect faces\n",
        "- Detect objects in the scene\n",
        "\n",
        "Keep in mind these models, especially the object detection, is trained on coco8 dataset only, future scope is to train it on a much larger dataset, discussed in the first YOLOv8_coco8.ipynb notebook. coco8 dataset only consists 4 images.\n",
        "\n",
        "**Note**: another method which passes the input picture first through the object detection model followed by face detection model was tested, but those results were not saved as the bounding boxes get cluttered.\n",
        "\n",
        "1) Now we aim to see how we can use the attributes of the detected objects to enhance this passage of photos to the second model. This can be done by , first detecting the presence of a `person` , if person is present we should be passing the photo to detecting the presence of a `face` on the second model.\n",
        "\n",
        "2) Training the first model (object detection) on a larger dataset is still pending and is a task left due time.\n",
        "\n",
        "3) Unfortunately the hugging face model we are using, the code generating it is not open source, I could not find it. Fortunately the datasets it was trained on is given, we could reverse engineer and build a model which combines both of them in a transfer learning fashion."
      ],
      "metadata": {
        "id": "dvxjJLX-QFwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mkUsQ1x_N_kS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}